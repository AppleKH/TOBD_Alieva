{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cvJRCgAZcjt"
      },
      "source": [
        "# Введение в обработку текста на естественном языке"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgxsIYnNZcjx"
      },
      "source": [
        "## Задачи для совместного разбора"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgXETNJrZcjy"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import re\n",
        "import pymorphy2\n",
        "from Levenshtein import distance as lev\n",
        "from scipy.spatial.distance import cosine\n",
        "from nltk.metrics.distance import edit_distance\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import FreqDist\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import csv\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pandas as pd\n",
        "from nltk.stem import SnowballStemmer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CEhLAU2Zcjz"
      },
      "source": [
        "1. Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "ERQnxL3vR6N0",
        "outputId": "3c5bf777-7175-4ba4-a596-796a96b64b76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Freq',\n",
              " 'w',\n",
              " 'и',\n",
              " 'в',\n",
              " 'я',\n",
              " 'с',\n",
              " 'а',\n",
              " 'к',\n",
              " 'у',\n",
              " 'о',\n",
              " 'н',\n",
              " 'п',\n",
              " 'ж',\n",
              " 'б',\n",
              " 'т',\n",
              " 'д',\n",
              " 'м',\n",
              " 'ч',\n",
              " 'з',\n",
              " 'г',\n",
              " 'е',\n",
              " 'р',\n",
              " 'э',\n",
              " 'л',\n",
              " 'х',\n",
              " 'ш',\n",
              " 'ф',\n",
              " 'ц',\n",
              " 'щ',\n",
              " 'й',\n",
              " 'ю',\n",
              " 'ы',\n",
              " 'ъ',\n",
              " 'ь',\n",
              " 'не',\n",
              " 'на',\n",
              " 'он',\n",
              " 'то',\n",
              " 'но',\n",
              " 'же',\n",
              " 'вы',\n",
              " 'по',\n",
              " 'да',\n",
              " 'за',\n",
              " 'бы',\n",
              " 'ты',\n",
              " 'от',\n",
              " 'из',\n",
              " 'ее',\n",
              " 'до',\n",
              " 'ну',\n",
              " 'ни',\n",
              " 'ли',\n",
              " 'уж',\n",
              " 'во',\n",
              " 'их',\n",
              " 'мы',\n",
              " 'со',\n",
              " 'ей',\n",
              " 'об',\n",
              " 'ко',\n",
              " 'ах',\n",
              " 'им',\n",
              " 'ка',\n",
              " 'та',\n",
              " 'пр',\n",
              " 'те',\n",
              " 'чт',\n",
              " 'ту',\n",
              " 'го',\n",
              " 'де',\n",
              " 'вс',\n",
              " 'эт',\n",
              " 'мо',\n",
              " 'ра',\n",
              " 'ст',\n",
              " 'ха',\n",
              " 'хе',\n",
              " 'ум',\n",
              " 'се',\n",
              " 'эх',\n",
              " 'гм',\n",
              " 'ме',\n",
              " 'св',\n",
              " 'ль',\n",
              " 'ег',\n",
              " 'пе',\n",
              " 'ва',\n",
              " 'са',\n",
              " 'ве',\n",
              " 'ох',\n",
              " 'бо',\n",
              " 'хо',\n",
              " 'че',\n",
              " 'сл',\n",
              " 'од',\n",
              " 'бе',\n",
              " 'мн',\n",
              " 'ай',\n",
              " 'ею',\n",
              " 'ос',\n",
              " 'ск',\n",
              " 'ви',\n",
              " 'ми',\n",
              " 'ма',\n",
              " 'сп',\n",
              " 'ба',\n",
              " 'ес',\n",
              " 'бу',\n",
              " 'гл',\n",
              " 'що',\n",
              " 'эй',\n",
              " 'ем',\n",
              " 'кр',\n",
              " 'см',\n",
              " 'др',\n",
              " 'лю',\n",
              " 'па',\n",
              " 'ро',\n",
              " 'зн',\n",
              " 'ле',\n",
              " 'як',\n",
              " 'тр',\n",
              " 'жи',\n",
              " 'ел',\n",
              " 'ус',\n",
              " 'фу',\n",
              " 'дв',\n",
              " 'ру',\n",
              " 'ал',\n",
              " 'ой',\n",
              " 'си',\n",
              " 'ду',\n",
              " 'вз',\n",
              " 'ещ',\n",
              " 'хи',\n",
              " 'чи',\n",
              " 'вд',\n",
              " 'ил',\n",
              " 'ух',\n",
              " 'ча',\n",
              " 'гр',\n",
              " 'пи',\n",
              " 'бл',\n",
              " 'ре',\n",
              " 'су',\n",
              " 'ге',\n",
              " 'ку',\n",
              " 'оп',\n",
              " 'жа',\n",
              " 'ис',\n",
              " 'оч',\n",
              " 'эк',\n",
              " 'дл',\n",
              " 'пл',\n",
              " 'ин',\n",
              " 'пу',\n",
              " 'фр',\n",
              " 'ан',\n",
              " 'бр',\n",
              " 'чу',\n",
              " 'му',\n",
              " 'ув',\n",
              " 'вп',\n",
              " 'кн',\n",
              " 'ив',\n",
              " 'ок',\n",
              " 'ад',\n",
              " 'лу',\n",
              " 'уг',\n",
              " 'вр',\n",
              " 'ло',\n",
              " 'це',\n",
              " 'гу',\n",
              " 'ла',\n",
              " 'ше',\n",
              " 'ср',\n",
              " 'ти',\n",
              " 'уд',\n",
              " 'фе',\n",
              " 'ди',\n",
              " 'тв',\n",
              " 'гд',\n",
              " 'сд',\n",
              " 'вн',\n",
              " 'ид',\n",
              " 'уб',\n",
              " 'щи',\n",
              " 'зд',\n",
              " 'уп',\n",
              " 'сч',\n",
              " 'уз',\n",
              " 'га',\n",
              " 'ог',\n",
              " 'ул',\n",
              " 'ша',\n",
              " 'ар',\n",
              " 'ут',\n",
              " 'фи',\n",
              " 'аж',\n",
              " 'ед',\n",
              " 'кт',\n",
              " 'гг',\n",
              " 'кл',\n",
              " 'сн',\n",
              " 'ук',\n",
              " 'зе',\n",
              " 'иг',\n",
              " 'зи',\n",
              " 'ки',\n",
              " 'ца',\n",
              " 'яр',\n",
              " 'дн',\n",
              " 'мя',\n",
              " 'сы',\n",
              " 'фа',\n",
              " 'вм',\n",
              " 'зл',\n",
              " 'ож',\n",
              " 'сю',\n",
              " 'шу',\n",
              " 'пя',\n",
              " 'тя',\n",
              " 'шл',\n",
              " 'шт',\n",
              " 'вл',\n",
              " 'ля',\n",
              " 'ор',\n",
              " 'хр',\n",
              " 'ще',\n",
              " 'ак',\n",
              " 'дя',\n",
              " 'ит',\n",
              " 'уч',\n",
              " 'ху',\n",
              " 'ши',\n",
              " 'фо',\n",
              " 'яв',\n",
              " 'би',\n",
              " 'ды',\n",
              " 'ры',\n",
              " 'уй',\n",
              " 'юг',\n",
              " 'вв',\n",
              " 'иб',\n",
              " 'кв',\n",
              " 'сб',\n",
              " 'сх',\n",
              " 'сь',\n",
              " 'зв',\n",
              " 'ол',\n",
              " 'тс',\n",
              " 'яд',\n",
              " 'аз',\n",
              " 'вч',\n",
              " 'ет',\n",
              " 'зу',\n",
              " 'ке',\n",
              " 'хл',\n",
              " 'аг',\n",
              " 'ев',\n",
              " 'еж',\n",
              " 'жд',\n",
              " 'ны',\n",
              " 'ов',\n",
              " 'пь',\n",
              " 'яс',\n",
              " 'вт',\n",
              " 'зо',\n",
              " 'ня',\n",
              " 'оз',\n",
              " 'оф',\n",
              " 'ош',\n",
              " 'ся',\n",
              " 'тю',\n",
              " 'уе',\n",
              " 'ун',\n",
              " 'уш',\n",
              " 'хм',\n",
              " 'ав',\n",
              " 'жу',\n",
              " 'мл',\n",
              " 'мм',\n",
              " 'ри',\n",
              " 'ть',\n",
              " 'чр',\n",
              " 'шк',\n",
              " 'ап',\n",
              " 'ас',\n",
              " 'нр',\n",
              " 'сг',\n",
              " 'сс',\n",
              " 'чш',\n",
              " 'юн',\n",
              " 'яй',\n",
              " 'ам',\n",
              " 'вг',\n",
              " 'ву',\n",
              " 'вх',\n",
              " 'дю',\n",
              " 'км',\n",
              " 'мг',\n",
              " 'ом',\n",
              " 'ощ',\n",
              " 'пы',\n",
              " 'рт',\n",
              " 'рю',\n",
              " 'ря',\n",
              " 'сф',\n",
              " 'сц',\n",
              " 'ур',\n",
              " 'хв',\n",
              " 'шп',\n",
              " 'шю',\n",
              " 'ая',\n",
              " 'бя',\n",
              " 'ги',\n",
              " 'гн',\n",
              " 'дж',\n",
              " 'ер',\n",
              " 'ик',\n",
              " 'ищ',\n",
              " 'съ',\n",
              " 'фл',\n",
              " 'чь',\n",
              " 'шо',\n",
              " 'яз',\n",
              " 'аи',\n",
              " 'ат',\n",
              " 'ау',\n",
              " 'вк',\n",
              " 'вя',\n",
              " 'ие',\n",
              " 'ий',\n",
              " 'кс',\n",
              " 'кх',\n",
              " 'тц',\n",
              " 'уа',\n",
              " 'цв',\n",
              " 'ци',\n",
              " 'эп',\n",
              " 'юх',\n",
              " 'ен',\n",
              " 'еф',\n",
              " 'ех',\n",
              " 'зы',\n",
              " 'иа',\n",
              " 'иж',\n",
              " 'ии',\n",
              " 'ио',\n",
              " 'ип',\n",
              " 'ич',\n",
              " 'лы',\n",
              " 'мс',\n",
              " 'мф',\n",
              " 'нс',\n",
              " 'ое',\n",
              " 'оц',\n",
              " 'пш',\n",
              " 'сж',\n",
              " 'сш',\n",
              " 'тщ',\n",
              " 'уф',\n",
              " 'цо',\n",
              " 'цу',\n",
              " 'чо',\n",
              " 'шш',\n",
              " 'эс',\n",
              " 'юм',\n",
              " 'ют',\n",
              " 'аб',\n",
              " 'аф',\n",
              " 'аш',\n",
              " 'бь',\n",
              " 'бю',\n",
              " 'вш',\n",
              " 'въ',\n",
              " 'гв',\n",
              " 'гю',\n",
              " 'дз',\n",
              " 'дм',\n",
              " 'дь',\n",
              " 'еш',\n",
              " 'жр',\n",
              " 'зг',\n",
              " 'зз',\n",
              " 'зр',\n",
              " 'иу',\n",
              " 'иф',\n",
              " 'кь',\n",
              " 'лб',\n",
              " 'лг',\n",
              " 'лж',\n",
              " 'лт',\n",
              " 'мр',\n",
              " 'мч',\n",
              " 'нь',\n",
              " 'нэ',\n",
              " 'ню',\n",
              " 'пт',\n",
              " 'сз',\n",
              " 'тк',\n",
              " 'тл',\n",
              " 'тт',\n",
              " 'тэ',\n",
              " 'уи',\n",
              " 'ущ',\n",
              " 'ую',\n",
              " 'фэ',\n",
              " 'цы',\n",
              " 'шв',\n",
              " 'шм',\n",
              " 'шь',\n",
              " 'ща',\n",
              " 'щу',\n",
              " 'ые',\n",
              " 'ый',\n",
              " 'ыч',\n",
              " 'эа',\n",
              " 'эл',\n",
              " 'эм',\n",
              " 'эн',\n",
              " 'эф',\n",
              " 'ээ',\n",
              " 'юб',\n",
              " 'юл',\n",
              " 'юс',\n",
              " 'яб',\n",
              " 'ян',\n",
              " 'ят',\n",
              " 'ях',\n",
              " 'ящ',\n",
              " 'что',\n",
              " 'как',\n",
              " 'это',\n",
              " 'все',\n",
              " 'его',\n",
              " 'так',\n",
              " 'она',\n",
              " 'мне',\n",
              " 'еще',\n",
              " 'вот',\n",
              " 'был',\n",
              " 'ему',\n",
              " 'нет',\n",
              " 'уже',\n",
              " 'вас',\n",
              " 'вам',\n",
              " 'или',\n",
              " 'для',\n",
              " 'они',\n",
              " 'тут',\n",
              " 'сам',\n",
              " 'чем',\n",
              " 'раз',\n",
              " 'там',\n",
              " 'где',\n",
              " 'под',\n",
              " 'без',\n",
              " 'ней',\n",
              " 'кто',\n",
              " 'мой',\n",
              " 'ним',\n",
              " 'тем',\n",
              " 'при',\n",
              " 'про',\n",
              " 'нас',\n",
              " 'них',\n",
              " 'мог',\n",
              " 'нее',\n",
              " 'эти',\n",
              " 'тот',\n",
              " 'два',\n",
              " 'том',\n",
              " 'всю',\n",
              " 'над',\n",
              " 'три',\n",
              " 'эту',\n",
              " 'лет',\n",
              " 'нем',\n",
              " 'нам',\n",
              " 'бог',\n",
              " 'вся',\n",
              " 'эта',\n",
              " 'моя',\n",
              " 'мое',\n",
              " 'оно',\n",
              " 'всг',\n",
              " 'пор',\n",
              " 'две',\n",
              " 'наш',\n",
              " 'мои',\n",
              " 'дня',\n",
              " 'тех',\n",
              " 'час',\n",
              " 'дом',\n",
              " 'ибо',\n",
              " 'мою',\n",
              " 'сих',\n",
              " 'нею',\n",
              " 'оба',\n",
              " 'вон',\n",
              " 'той',\n",
              " 'вид',\n",
              " 'год',\n",
              " 'ваш',\n",
              " 'дал',\n",
              " 'сел',\n",
              " 'кое',\n",
              " 'ума',\n",
              " 'сто',\n",
              " 'рад',\n",
              " 'дай',\n",
              " 'обо',\n",
              " 'чай',\n",
              " 'пол',\n",
              " 'рук',\n",
              " 'шел',\n",
              " 'нос',\n",
              " 'дам',\n",
              " 'обе',\n",
              " 'дни',\n",
              " 'сей',\n",
              " 'сон',\n",
              " 'кем',\n",
              " 'муж',\n",
              " 'сын',\n",
              " 'имя',\n",
              " 'жил',\n",
              " 'рот',\n",
              " 'дух',\n",
              " 'сил',\n",
              " 'мир',\n",
              " 'ног',\n",
              " 'уме',\n",
              " 'пан',\n",
              " 'сне',\n",
              " 'ста',\n",
              " 'шею',\n",
              " 'сад',\n",
              " 'чаю',\n",
              " 'изо',\n",
              " 'сво',\n",
              " 'миг',\n",
              " 'век',\n",
              " 'мол',\n",
              " 'пот',\n",
              " 'шум',\n",
              " 'дел',\n",
              " 'дед',\n",
              " 'иди',\n",
              " 'пер',\n",
              " 'лиц',\n",
              " 'сем',\n",
              " 'лес',\n",
              " 'тек',\n",
              " 'шла',\n",
              " 'шаг',\n",
              " 'очи',\n",
              " 'душ',\n",
              " 'суд',\n",
              " 'гор',\n",
              " 'пре',\n",
              " 'тон',\n",
              " 'иду',\n",
              " 'тол',\n",
              " 'лег',\n",
              " 'шли',\n",
              " 'пил',\n",
              " 'зна',\n",
              " 'али',\n",
              " 'ими',\n",
              " 'ком',\n",
              " 'мен',\n",
              " 'рас',\n",
              " 'ухо',\n",
              " 'сию',\n",
              " 'кой',\n",
              " 'уши',\n",
              " 'иль',\n",
              " 'одн',\n",
              " 'бол',\n",
              " 'пос',\n",
              " 'вне',\n",
              " 'буд',\n",
              " 'кот',\n",
              " 'лбу',\n",
              " 'кум',\n",
              " 'аль',\n",
              " 'жду',\n",
              " 'лоб',\n",
              " 'ска',\n",
              " 'сна',\n",
              " 'стр',\n",
              " 'вор',\n",
              " 'шее',\n",
              " 'жив',\n",
              " 'меж',\n",
              " 'гов',\n",
              " 'сие',\n",
              " 'ест',\n",
              " 'лев',\n",
              " 'воз',\n",
              " 'фон',\n",
              " 'мож',\n",
              " 'дру',\n",
              " 'кхи',\n",
              " 'еду',\n",
              " 'себ',\n",
              " 'вел',\n",
              " 'увы',\n",
              " 'жид',\n",
              " 'род',\n",
              " 'теб',\n",
              " 'усы',\n",
              " 'шло',\n",
              " 'пок',\n",
              " 'губ',\n",
              " 'ишь',\n",
              " 'бал',\n",
              " 'ког',\n",
              " 'даж',\n",
              " 'дар',\n",
              " 'зло',\n",
              " 'мно',\n",
              " 'тог',\n",
              " 'быт',\n",
              " 'даю',\n",
              " 'сло',\n",
              " 'теп',\n",
              " 'ост',\n",
              " 'бес',\n",
              " 'нег',\n",
              " 'чин',\n",
              " 'тою',\n",
              " 'хот',\n",
              " 'бек',\n",
              " 'бок',\n",
              " 'гол',\n",
              " 'жен',\n",
              " 'чей',\n",
              " 'вер',\n",
              " 'луч',\n",
              " 'нес',\n",
              " 'поч',\n",
              " 'вдр',\n",
              " 'жар',\n",
              " 'люб',\n",
              " 'опя',\n",
              " 'нож',\n",
              " 'ряд',\n",
              " 'вес',\n",
              " 'гла',\n",
              " 'дым',\n",
              " 'ход',\n",
              " 'всь',\n",
              " 'зла',\n",
              " 'неп',\n",
              " 'чуб',\n",
              " 'рту',\n",
              " 'слу',\n",
              " 'сны',\n",
              " 'чел',\n",
              " 'отв',\n",
              " 'сме',\n",
              " 'ник',\n",
              " 'пар',\n",
              " 'бил',\n",
              " 'есл',\n",
              " 'мал',\n",
              " 'оче',\n",
              " 'рта',\n",
              " 'уст',\n",
              " 'вед',\n",
              " 'кон',\n",
              " 'сия',\n",
              " 'баб',\n",
              " 'пов',\n",
              " 'рай',\n",
              " 'дум',\n",
              " 'дол',\n",
              " 'пра',\n",
              " 'сим',\n",
              " 'дне',\n",
              " 'зам',\n",
              " 'ива',\n",
              " 'име',\n",
              " 'нак',\n",
              " 'пом',\n",
              " 'поп',\n",
              " 'чьи',\n",
              " 'быв',\n",
              " 'дав',\n",
              " 'зол',\n",
              " 'пью',\n",
              " 'шеи',\n",
              " 'ниб',\n",
              " 'сер',\n",
              " 'лжи',\n",
              " 'соб',\n",
              " 'тип',\n",
              " 'шут',\n",
              " 'яко',\n",
              " 'бла',\n",
              " 'вре',\n",
              " 'дна',\n",
              " 'мил',\n",
              " 'нач',\n",
              " 'раб',\n",
              " 'чер',\n",
              " 'чья',\n",
              " 'нап',\n",
              " 'обр',\n",
              " 'сов',\n",
              " 'гос',\n",
              " 'идя',\n",
              " 'пел',\n",
              " 'пет',\n",
              " 'вос',\n",
              " 'ден',\n",
              " 'пал',\n",
              " 'све',\n",
              " 'спи',\n",
              " 'цел',\n",
              " 'бой',\n",
              " 'жиз',\n",
              " 'ищу',\n",
              " 'каж',\n",
              " 'пон',\n",
              " 'суп',\n",
              " 'хор',\n",
              " 'сле',\n",
              " 'лад',\n",
              " 'пир',\n",
              " 'сии',\n",
              " 'бед',\n",
              " 'зал',\n",
              " 'ура',\n",
              " 'але',\n",
              " 'зас',\n",
              " 'кра',\n",
              " 'мес',\n",
              " 'око',\n",
              " 'пус',\n",
              " 'ско',\n",
              " 'эге',\n",
              " 'выс',\n",
              " 'дер',\n",
              " 'рос',\n",
              " 'боя',\n",
              " 'зак',\n",
              " 'кол',\n",
              " 'оди',\n",
              " 'ото',\n",
              " 'пав',\n",
              " 'поз',\n",
              " 'смо',\n",
              " 'спр',\n",
              " 'тих',\n",
              " 'тож',\n",
              " 'заб',\n",
              " 'зав',\n",
              " 'лба',\n",
              " 'мел',\n",
              " 'отк',\n",
              " 'дно',\n",
              " 'зап',\n",
              " 'кня',\n",
              " 'люд',\n",
              " 'мат',\n",
              " 'мая',\n",
              " 'нед',\n",
              " 'пес',\n",
              " 'сос',\n",
              " 'уму',\n",
              " 'чье',\n",
              " 'веч',\n",
              " 'пис',\n",
              " 'уху',\n",
              " 'бар',\n",
              " 'вст',\n",
              " 'гул',\n",
              " 'ища',\n",
              " 'мер',\n",
              " 'наз',\n",
              " 'ром',\n",
              " 'сде',\n",
              " 'спа',\n",
              " 'ага',\n",
              " 'бро',\n",
              " 'доб',\n",
              " 'дов',\n",
              " 'зад',\n",
              " 'кри',\n",
              " 'тре',\n",
              " 'вод',\n",
              " 'ели',\n",
              " 'осо',\n",
              " 'пой',\n",
              " 'рев',\n",
              " 'вин',\n",
              " 'вру',\n",
              " 'дор',\n",
              " 'иск',\n",
              " 'лгу',\n",
              " 'лик',\n",
              " 'нич',\n",
              " 'ужа',\n",
              " 'щек',\n",
              " 'вол',\n",
              " 'дос',\n",
              " 'еле',\n",
              " 'зат',\n",
              " 'ино',\n",
              " 'лат',\n",
              " 'пла',\n",
              " 'пош',\n",
              " 'сор',\n",
              " 'бра',\n",
              " 'гру',\n",
              " 'заг',\n",
              " 'мин',\n",
              " 'нар',\n",
              " 'пож',\n",
              " 'сту',\n",
              " 'точ',\n",
              " 'хоч',\n",
              " 'дев',\n",
              " 'зря',\n",
              " 'меч',\n",
              " 'мыс',\n",
              " 'неу',\n",
              " 'сте',\n",
              " 'улы',\n",
              " 'зде',\n",
              " 'исп',\n",
              " 'кар',\n",
              " 'кро',\n",
              " 'кур',\n",
              " 'лай',\n",
              " 'лед',\n",
              " 'нав',\n",
              " 'нев',\n",
              " 'нео',\n",
              " 'нов',\n",
              " 'ока',\n",
              " 'пуф',\n",
              " 'реш',\n",
              " 'руб',\n",
              " 'сак',\n",
              " 'сок',\n",
              " 'тво',\n",
              " 'уха',\n",
              " 'вск',\n",
              " 'гам',\n",
              " 'ген',\n",
              " 'мед',\n",
              " 'наг',\n",
              " 'отд',\n",
              " 'рус',\n",
              " 'слы',\n",
              " 'взг',\n",
              " 'вой',\n",
              " 'воп',\n",
              " 'выш',\n",
              " 'дон',\n",
              " 'ешь',\n",
              " 'жел',\n",
              " 'зов',\n",
              " 'мук',\n",
              " 'неш',\n",
              " 'ниц',\n",
              " 'обс',\n",
              " 'оне',\n",
              " 'пря',\n",
              " 'сыр',\n",
              " 'уви',\n",
              " 'узн',\n",
              " 'худ',\n",
              " 'эка',\n",
              " 'взд',\n",
              " 'впе',\n",
              " 'гля',\n",
              " 'дуб',\n",
              " 'дур',\n",
              " 'ела',\n",
              " 'игр',\n",
              " 'изб',\n",
              " 'лиш',\n",
              " 'обл',\n",
              " 'ого',\n",
              " 'пей',\n",
              " 'пух',\n",
              " 'пят',\n",
              " 'ран',\n",
              " 'сла',\n",
              " 'тыс',\n",
              " 'укр',\n",
              " 'фед',\n",
              " 'фра',\n",
              " 'щоб',\n",
              " 'бей',\n",
              " 'бык',\n",
              " 'взя',\n",
              " 'гро',\n",
              " 'дво',\n",
              " 'жал',\n",
              " 'изв',\n",
              " 'куд',\n",
              " 'мух',\n",
              " 'ноч',\n",
              " 'пле',\n",
              " 'рак',\n",
              " 'ред',\n",
              " 'чег',\n",
              " 'чув',\n",
              " 'шея',\n",
              " 'бер',\n",
              " 'бор',\n",
              " 'вал',\n",
              " 'вме',\n",
              " 'глу',\n",
              " 'гоп',\n",
              " 'дет',\n",
              " 'док',\n",
              " 'ищи',\n",
              " 'кох',\n",
              " 'кре',\n",
              " 'нах',\n",
              " 'объ',\n",
              " 'ожи',\n",
              " 'тер',\n",
              " 'тро',\n",
              " 'тсс',\n",
              " 'уби',\n",
              " 'чет',\n",
              " 'эко',\n",
              " 'бел',\n",
              " 'быс',\n",
              " 'впр',\n",
              " 'зах',\n",
              " 'кру',\n",
              " 'мар',\n",
              " 'нек',\n",
              " 'нуж',\n",
              " 'поб',\n",
              " 'пог',\n",
              " 'рим',\n",
              " 'роз',\n",
              " 'соо',\n",
              " 'спо',\n",
              " 'сыт',\n",
              " 'тел',\n",
              " 'тра',\n",
              " 'уго',\n",
              " 'чес',\n",
              " 'юге',\n",
              " 'яму',\n",
              " 'бум',\n",
              " 'вез',\n",
              " 'воо',\n",
              " 'гра',\n",
              " 'жан',\n",
              " 'изд',\n",
              " 'кап',\n",
              " 'лех',\n",
              " 'отц',\n",
              " 'раю',\n",
              " 'ров',\n",
              " 'рты',\n",
              " 'сид',\n",
              " 'учи',\n",
              " 'вып',\n",
              " 'гад',\n",
              " 'жди',\n",
              " 'каз',\n",
              " 'кос',\n",
              " 'лез',\n",
              " 'мит',\n",
              " 'неб',\n",
              " 'отр',\n",
              " 'рок',\n",
              " 'рыб',\n",
              " 'сан',\n",
              " 'сек',\n",
              " 'сну',\n",
              " 'уве',\n",
              " 'уди',\n",
              " 'ухе',\n",
              " 'чад',\n",
              " 'чая',\n",
              " 'чис',\n",
              " 'чут',\n",
              " 'акт',\n",
              " 'вов',\n",
              " 'всп',\n",
              " 'дню',\n",
              " 'дул',\n",
              " 'ежа',\n",
              " 'жит',\n",
              " ...]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#ВАРИАНТ 1\n",
        "p = re.compile(r'[a-zA-Zа-яА-ЯёЁ]+') \n",
        "with open('litw-win.txt', encoding='utf8') as f:\n",
        "    words = p.findall(f.read())\n",
        "\n",
        "words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JXaF47KZcjz",
        "outputId": "8dabbe31-bd2f-463b-964c-369b8c0886ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "с величайшим усилием выбравшись из потока убегающих людей кутузов со свитой уменьшившейся вдвое поехал на звуки выстрелов русских орудий\n"
          ]
        }
      ],
      "source": [
        "text = '''с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий'''.split(' ')\n",
        "t=[]\n",
        "for i in text:\n",
        "    if i in words:\n",
        "        t.append(i)\n",
        "    else:\n",
        "        lm=lev(i, words[0])\n",
        "        n=words[0]\n",
        "        for ii in words:\n",
        "            if lev(i, ii)<lm:\n",
        "                lm=lev(i, ii)\n",
        "                n=ii\n",
        "        t.append(n)\n",
        "print(\" \".join(t))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oa-dg8xAZcj0"
      },
      "source": [
        "2. Разбейте текст из формулировки задания 1 на слова; проведите стемминг и лемматизацию слов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qd8iGI_qR6N3",
        "outputId": "cbbb5681-e1cf-4396-8c75-c43018ac5026"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "слов Считайте стемминг: счита лемматизацию: считать\n",
            "слов слова стемминг: слов лемматизацию: слово\n",
            "слов из стемминг: из лемматизацию: из\n",
            "слов файла стемминг: файл лемматизацию: файл\n",
            "слов litw стемминг: litw лемматизацию: litw\n",
            "слов win стемминг: win лемматизацию: win\n",
            "слов txt стемминг: txt лемматизацию: txt\n",
            "слов и стемминг: и лемматизацию: и\n",
            "слов запишите стемминг: запиш лемматизацию: записать\n",
            "слов их стемминг: их лемматизацию: они\n",
            "слов в стемминг: в лемматизацию: в\n",
            "слов список стемминг: список лемматизацию: список\n",
            "слов words стемминг: words лемматизацию: words\n",
            "слов В стемминг: в лемматизацию: в\n",
            "слов заданном стемминг: зада лемматизацию: задать\n",
            "слов предложении стемминг: предложен лемматизацию: предложение\n",
            "слов исправьте стемминг: исправьт лемматизацию: исправить\n",
            "слов все стемминг: все лемматизацию: всё\n",
            "слов опечатки стемминг: опечатк лемматизацию: опечатка\n",
            "слов заменив стемминг: замен лемматизацию: заменить\n",
            "слов слова стемминг: слов лемматизацию: слово\n",
            "слов с стемминг: с лемматизацию: с\n",
            "слов опечатками стемминг: опечатк лемматизацию: опечатка\n",
            "слов на стемминг: на лемматизацию: на\n",
            "слов ближайшие стемминг: ближайш лемматизацию: близкий\n",
            "слов в стемминг: в лемматизацию: в\n",
            "слов смысле стемминг: смысл лемматизацию: смысл\n",
            "слов расстояния стемминг: расстоян лемматизацию: расстояние\n",
            "слов Левенштейна стемминг: левенштейн лемматизацию: левенштейн\n",
            "слов к стемминг: к лемматизацию: к\n",
            "слов ним стемминг: ним лемматизацию: они\n",
            "слов слова стемминг: слов лемматизацию: слово\n",
            "слов из стемминг: из лемматизацию: из\n",
            "слов списка стемминг: списк лемматизацию: список\n",
            "слов words стемминг: words лемматизацию: words\n",
            "слов Считайте стемминг: счита лемматизацию: считать\n",
            "слов что стемминг: что лемматизацию: что\n",
            "слов в стемминг: в лемматизацию: в\n",
            "слов слове стемминг: слов лемматизацию: слово\n",
            "слов есть стемминг: ест лемматизацию: есть\n",
            "слов опечатка стемминг: опечатк лемматизацию: опечатка\n",
            "слов если стемминг: есл лемматизацию: если\n",
            "слов данное стемминг: дан лемматизацию: данный\n",
            "слов слово стемминг: слов лемматизацию: слово\n",
            "слов не стемминг: не лемматизацию: не\n",
            "слов содержится стемминг: содерж лемматизацию: содержаться\n",
            "слов в стемминг: в лемматизацию: в\n",
            "слов списке стемминг: списк лемматизацию: список\n",
            "слов words стемминг: words лемматизацию: words\n"
          ]
        }
      ],
      "source": [
        "morph = pymorphy2.MorphAnalyzer()\n",
        "text = '''1. Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`.'''\n",
        "text=p.findall(text)\n",
        "snb = SnowballStemmer('russian')\n",
        "for i in text:\n",
        "    print('слов',i,'стемминг:', snb.stem(i),'лемматизацию:',morph.parse(i)[0].normalized.word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayoUZbQQZcj0"
      },
      "source": [
        "3. Преобразуйте предложения из формулировки задания 1 в векторы при помощи `CountVectorizer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZozfVDM4R6N5",
        "outputId": "a4f431c8-8f37-4f25-ef6f-82df17144ee9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Исходный текст:\n",
            "['Считайте слова из файла litw-win.txt и запишите их в список words', 'В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка words', 'Считайте, что в слове есть опечатка, если данное слово не содержится в списке words.']\n",
            "Найденные слова в предложениях:\n",
            "['litw', 'txt', 'win', 'words', 'ближайшие', 'все', 'данное', 'если', 'есть', 'заданном', 'заменив', 'запишите', 'из', 'исправьте', 'их', 'левенштейна', 'на', 'не', 'ним', 'опечатка', 'опечатками', 'опечатки', 'предложении', 'расстояния', 'слова', 'слове', 'слово', 'смысле', 'содержится', 'списка', 'списке', 'список', 'считайте', 'файла', 'что']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>litw</th>\n",
              "      <th>txt</th>\n",
              "      <th>win</th>\n",
              "      <th>words</th>\n",
              "      <th>ближайшие</th>\n",
              "      <th>все</th>\n",
              "      <th>данное</th>\n",
              "      <th>если</th>\n",
              "      <th>есть</th>\n",
              "      <th>заданном</th>\n",
              "      <th>...</th>\n",
              "      <th>слове</th>\n",
              "      <th>слово</th>\n",
              "      <th>смысле</th>\n",
              "      <th>содержится</th>\n",
              "      <th>списка</th>\n",
              "      <th>списке</th>\n",
              "      <th>список</th>\n",
              "      <th>считайте</th>\n",
              "      <th>файла</th>\n",
              "      <th>что</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 35 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   litw  txt  win  words  ближайшие  все  данное  если  есть  заданном  ...  \\\n",
              "0     1    1    1      1          0    0       0     0     0         0  ...   \n",
              "1     0    0    0      1          1    1       0     0     0         1  ...   \n",
              "2     0    0    0      1          0    0       1     1     1         0  ...   \n",
              "\n",
              "   слове  слово  смысле  содержится  списка  списке  список  считайте  файла  \\\n",
              "0      0      0       0           0       0       0       1         1      1   \n",
              "1      0      0       1           0       1       0       0         0      0   \n",
              "2      1      1       0           1       0       1       0         1      0   \n",
              "\n",
              "   что  \n",
              "0    0  \n",
              "1    0  \n",
              "2    1  \n",
              "\n",
              "[3 rows x 35 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t = \"Считайте слова из файла litw-win.txt и запишите их в список words. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка words. Считайте, что в слове есть опечатка, если данное слово не содержится в списке words.\".split('. ')\n",
        "print(f\"Исходный текст:\\n{t}\")\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(t)\n",
        "cols = vectorizer.get_feature_names()\n",
        "print(f\"Найденные слова в предложениях:\\n{cols}\")\n",
        "df = pd.DataFrame(data=X.toarray(), columns=cols)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNoRzZdQZcj1"
      },
      "source": [
        "## Лабораторная работа 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy7s7_45Zcj1"
      },
      "source": [
        "### Расстояние редактирования"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEq_HK3bZcj2"
      },
      "source": [
        "1.1 Загрузите предобработанные описания рецептов из файла `preprocessed_descriptions.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). \n",
        "\n",
        "Примечание: файл preprocessed_description.csv содержит в столбце full_description названия рецепта, его краткое описание, а также все шаги приготовления (использовать файлы recipes_sample.csv и step_sample.xml)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJkblyPaR6N8",
        "outputId": "ddb9310c-cbec-4189-f940-12dc065ccc3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['tapenade',\n",
              " 'tasteposting',\n",
              " 'served-',\n",
              " 'tastes.we',\n",
              " '101039',\n",
              " 'guidry',\n",
              " 'zwt',\n",
              " 'time.there',\n",
              " 'yal',\n",
              " 'wake',\n",
              " 'purree',\n",
              " 'variation.i',\n",
              " 'elegant-looking',\n",
              " '360ml',\n",
              " 'gourmeti',\n",
              " 'hand-rolled',\n",
              " 'cantaloup',\n",
              " 'often.given',\n",
              " 'banditos.a',\n",
              " 'waterfrom',\n",
              " 'bottega',\n",
              " 'cool.dh',\n",
              " 'applying',\n",
              " 'dictionaries',\n",
              " 'livers',\n",
              " 'loaf',\n",
              " 'stairs',\n",
              " 'cabbage.how',\n",
              " 'directions.an',\n",
              " 'blintzes',\n",
              " 'beets.from',\n",
              " 'mayo-laden',\n",
              " 'different.very',\n",
              " 'potatoes.if',\n",
              " 'peasthis',\n",
              " 'dayi',\n",
              " 'ahead.add',\n",
              " 'nadia',\n",
              " 'strayed',\n",
              " 'carefree',\n",
              " 'nuts.purim',\n",
              " 'effort.i',\n",
              " 'purge',\n",
              " 'bursa',\n",
              " 'seafood.in',\n",
              " '50550.',\n",
              " 'saurerkraut',\n",
              " 'arizona.from',\n",
              " 'lewis',\n",
              " 'haystacks',\n",
              " 'butter-nut',\n",
              " 'moneymaker',\n",
              " 'nondairy',\n",
              " 'buds.few',\n",
              " 'teriffic',\n",
              " 'cakes…always',\n",
              " '1399',\n",
              " 'crockers',\n",
              " 'oven.quick',\n",
              " 'devlin',\n",
              " 'revisions',\n",
              " 'time.tender',\n",
              " 'lavash',\n",
              " 'synergistically',\n",
              " 'goosey',\n",
              " 'ginger',\n",
              " 'good.cooking',\n",
              " 'interior.i',\n",
              " 'form.the',\n",
              " '210983',\n",
              " 'precut',\n",
              " 'radically',\n",
              " 'murukku',\n",
              " \"'paté\",\n",
              " 'ketjap',\n",
              " 'vanilla.what',\n",
              " 'often.delicious',\n",
              " 'long.i',\n",
              " 'meat.an',\n",
              " 'shoveling',\n",
              " 'actual',\n",
              " 'serranos',\n",
              " 'realistically',\n",
              " 'ready-to-use',\n",
              " 'been',\n",
              " 'bittersweet',\n",
              " 'atco',\n",
              " 'kenney',\n",
              " 'crenberries',\n",
              " 'aleppo',\n",
              " 'grean',\n",
              " 'canapes',\n",
              " 'czechoslovak',\n",
              " 'shewchuk.this',\n",
              " 'bodies',\n",
              " 'season-sliced',\n",
              " 'day.i',\n",
              " 'recipeadapted',\n",
              " 'eggless',\n",
              " 'diets.tuna',\n",
              " 'grms',\n",
              " 'nothing',\n",
              " 'straight',\n",
              " 'organization',\n",
              " 'windfalls',\n",
              " 'alsace',\n",
              " 'fruitier',\n",
              " 'barbecue.this',\n",
              " 'goodman',\n",
              " 'like.do',\n",
              " '64793',\n",
              " 'set',\n",
              " '3/4-cup',\n",
              " 'cooky',\n",
              " 'maxine',\n",
              " 'costco.do',\n",
              " 'killers',\n",
              " 'mulch',\n",
              " '32g',\n",
              " 'babara',\n",
              " 'machine.you',\n",
              " 'propel',\n",
              " 'poly',\n",
              " 'boysenberries',\n",
              " 'vietnamese',\n",
              " 'falooda',\n",
              " 'allrecipes.com.can',\n",
              " 'needed.friends',\n",
              " 'jammu',\n",
              " 'side-sized',\n",
              " 'recipes',\n",
              " 'indonesian',\n",
              " '1999if',\n",
              " 'ab',\n",
              " 'lebovitz',\n",
              " 'numbing',\n",
              " 'forelle',\n",
              " 'anchovies.i',\n",
              " 'timesaver',\n",
              " 'nice.the',\n",
              " 'radarrange.i',\n",
              " \"'04\",\n",
              " 'boredom',\n",
              " 'israel.this',\n",
              " 'office.this',\n",
              " 'eumundie',\n",
              " 'cob.corn',\n",
              " 'fussed',\n",
              " \"dip'deliciously\",\n",
              " 'glaze.another',\n",
              " 'iraqi',\n",
              " 'refrigeration.this',\n",
              " 'powdervegan',\n",
              " 'spiral-cut',\n",
              " 'kheer',\n",
              " 'thailand',\n",
              " 'slimmed-down',\n",
              " 'mind-blowing',\n",
              " 'briami',\n",
              " 'schnitzel',\n",
              " 'holydays',\n",
              " 'homework',\n",
              " 'malla',\n",
              " 'gazillion',\n",
              " 'olsen',\n",
              " 'ranging',\n",
              " 'head-to-toe',\n",
              " 'sarasota',\n",
              " 'howard-',\n",
              " 'them.tasty',\n",
              " 'designers',\n",
              " 'simple.this',\n",
              " 'livethis',\n",
              " 'flux',\n",
              " 'tragedy',\n",
              " 'valerie',\n",
              " 'meal.great',\n",
              " 'float.three',\n",
              " 'cornflakesif',\n",
              " 'present.we',\n",
              " 'emergen-c',\n",
              " 'tyke',\n",
              " 'drowsy',\n",
              " 'pizza.so',\n",
              " 'desciption',\n",
              " 'rounds.an',\n",
              " 'ooey',\n",
              " 'wala',\n",
              " 'optional.my',\n",
              " '2.5',\n",
              " 'survival',\n",
              " 'calculate',\n",
              " '41',\n",
              " 'mother-in-law.it',\n",
              " 'byessar',\n",
              " 'mins',\n",
              " 'flavor.could',\n",
              " 'collection.i',\n",
              " 'chili.i',\n",
              " 'eating.an',\n",
              " 'merry',\n",
              " 'sherman',\n",
              " '147',\n",
              " 'eel',\n",
              " 'surimi',\n",
              " '8-ounce',\n",
              " 'finicky',\n",
              " 'diet.after',\n",
              " 'smoothh.the',\n",
              " 'bittman.this',\n",
              " 'green',\n",
              " 'texture.caramelized',\n",
              " 'bulgaria',\n",
              " 'servings.all',\n",
              " 'living.sticky',\n",
              " 'chief',\n",
              " 'food.for',\n",
              " 'tequila',\n",
              " 'parsnips',\n",
              " 'good.no',\n",
              " 'hazan',\n",
              " 'twinkle',\n",
              " 're-fridge',\n",
              " 'spikes',\n",
              " 'blts',\n",
              " 'form',\n",
              " 'almondsthis',\n",
              " 'rice.great',\n",
              " 'christ',\n",
              " \"'temperance\",\n",
              " 'kolu',\n",
              " 'taqueria.i',\n",
              " 'e-mealz',\n",
              " 'souls',\n",
              " 'tenderloin.for',\n",
              " 'yet.chinese',\n",
              " 'massachusetts.this',\n",
              " '//feaston.wordpress.com/2009/10/12/blushing-pork-loin/we',\n",
              " '.',\n",
              " 'nigel',\n",
              " 'milk.fresh',\n",
              " '2.95',\n",
              " 'voyage',\n",
              " 'vegetarian/carnivores',\n",
              " 're',\n",
              " 'domain.this',\n",
              " 'alfredo',\n",
              " 'lot-this',\n",
              " '86',\n",
              " '95mg',\n",
              " 'receptions',\n",
              " 'squid',\n",
              " 'film.this',\n",
              " 'saltfiskur',\n",
              " 'refrigerate.recipe',\n",
              " 'nelda',\n",
              " 'carotenes',\n",
              " 'winter',\n",
              " 'fiddlely',\n",
              " 'syrupthis',\n",
              " 'burritos.my',\n",
              " 'ayam',\n",
              " 'shern',\n",
              " 'list.wonderful',\n",
              " 'performances',\n",
              " 'priscilla',\n",
              " 'kraftfoods',\n",
              " 'tecate',\n",
              " 'casing',\n",
              " 'roasting.this',\n",
              " 'bruschetta',\n",
              " 'diabretic',\n",
              " 'ranks',\n",
              " 'recipe.top',\n",
              " '1lb',\n",
              " 'taste.elegant',\n",
              " 'butteriness',\n",
              " 'machine.a',\n",
              " 'knife.this',\n",
              " 'yumhave',\n",
              " 'auto',\n",
              " 'misc',\n",
              " 'bubblin',\n",
              " 'wonderfullyba',\n",
              " 'prune',\n",
              " 'wakes',\n",
              " 'collins',\n",
              " 'duxbury',\n",
              " 'sending',\n",
              " 'decidely',\n",
              " 'meats.from',\n",
              " \"'tortilla\",\n",
              " 'juice.zip',\n",
              " 'servings.when',\n",
              " 'category.i',\n",
              " 'cubes',\n",
              " 'posing',\n",
              " 'gallery',\n",
              " \"don't.this\",\n",
              " 'thot',\n",
              " 'cookbook.plan',\n",
              " 'imparting',\n",
              " 'warm.grilled',\n",
              " 'dfrom',\n",
              " 'minichips',\n",
              " 'vanilla.you',\n",
              " 'fiona',\n",
              " 'gaus.this',\n",
              " 'register',\n",
              " 'color.onion',\n",
              " 'incredible',\n",
              " 'merguez',\n",
              " 'chefeasy',\n",
              " 'yummylicious',\n",
              " 'business.from',\n",
              " 'anyday',\n",
              " 'cocktailsaduki',\n",
              " 'meal.it',\n",
              " 'peanut/tomato',\n",
              " 'greeting',\n",
              " 'quick-to-fix',\n",
              " 'wide',\n",
              " 'lunch.elegant',\n",
              " 'crockeri',\n",
              " 'you.gourmet',\n",
              " 'try.when',\n",
              " 'bisque.this',\n",
              " \"'pizza\",\n",
              " 'guerrero',\n",
              " 'benefit',\n",
              " 'velvet',\n",
              " 'dearborn',\n",
              " '206003.these',\n",
              " 'lapanja',\n",
              " 'sitequick',\n",
              " 'ready-made',\n",
              " 'tripled.this',\n",
              " 'reputations',\n",
              " 'colder',\n",
              " '//www.elanaspantry.com/cucumber-avocado-gazpacho/what',\n",
              " 'freezing.a',\n",
              " 'months.my',\n",
              " 'comparatively',\n",
              " 'anti',\n",
              " 'sauces.published',\n",
              " 'healthieri',\n",
              " 'pale-green',\n",
              " 'burst',\n",
              " 'demolished.another',\n",
              " 'proximity',\n",
              " 'done.learnt',\n",
              " 'oooooh',\n",
              " 'milk.if',\n",
              " 'douvre.i',\n",
              " 'fix.a',\n",
              " 'molecular',\n",
              " 'juiciness',\n",
              " 'walnuts.a',\n",
              " 'setting',\n",
              " 'cow-man.no',\n",
              " 'crêpes',\n",
              " 'want.you',\n",
              " 'cookie.my',\n",
              " \"'taco\",\n",
              " 'fallen',\n",
              " 'choice.serve',\n",
              " 'elecrtic',\n",
              " 'tin.based',\n",
              " 'oscar',\n",
              " 'insteada',\n",
              " 'dietary',\n",
              " 'padding',\n",
              " 'kefir',\n",
              " 'healthier.this',\n",
              " 'terre',\n",
              " 'drinker',\n",
              " 'liquers',\n",
              " 'roast/loaf',\n",
              " 'caribana',\n",
              " 'focusing',\n",
              " 'blackie',\n",
              " 'ceratin',\n",
              " 'figueroa',\n",
              " 'recipespickled',\n",
              " 'pep',\n",
              " 'pan-fry',\n",
              " 'provence',\n",
              " 'ambrose',\n",
              " 'forgetting',\n",
              " '20ml',\n",
              " 'mild',\n",
              " 'scallops.coquito',\n",
              " 'steamboat',\n",
              " 'unfair',\n",
              " 'counts',\n",
              " 'booster',\n",
              " 'accompany',\n",
              " 'request.i',\n",
              " 'figs',\n",
              " 'peeps',\n",
              " 'momokawa',\n",
              " 'chambersburg',\n",
              " 'names',\n",
              " 'evening.from',\n",
              " 'x-mas',\n",
              " 'dressing.this',\n",
              " 'wonderful.the',\n",
              " 'sunbeam',\n",
              " 'ox-tail',\n",
              " 'website.365',\n",
              " 'edy',\n",
              " 'builder',\n",
              " 'toh.this',\n",
              " 'baigan',\n",
              " 'smooth',\n",
              " '9th',\n",
              " 'age-old',\n",
              " 'elmotoo',\n",
              " '4.8',\n",
              " 'sliceable',\n",
              " 'sodeliciousdairyfree.com',\n",
              " 'mine.this',\n",
              " 'seconds.i',\n",
              " 'hilton',\n",
              " 'flat-out',\n",
              " 'crackers.the',\n",
              " 'corning',\n",
              " 'pot.traditionally',\n",
              " 'seem',\n",
              " 'too.vegetarian',\n",
              " 'places',\n",
              " 'nl',\n",
              " 'wow-ed',\n",
              " 'cooking-by-country',\n",
              " 'drink.the',\n",
              " 'great-grandmother',\n",
              " 's-i-l',\n",
              " 'using.got',\n",
              " 'evening.goes',\n",
              " 'dinner.this',\n",
              " 'snickerdoodle',\n",
              " 'delicious.sweet',\n",
              " 'brook',\n",
              " 'goooood',\n",
              " 'seuss',\n",
              " 'substitutepide',\n",
              " 'interchanging',\n",
              " 'gems',\n",
              " '105',\n",
              " 'angina',\n",
              " 'productgroup=',\n",
              " 'adhd',\n",
              " 'www.weightwatchers.comthis',\n",
              " 'enough.taken',\n",
              " 'dumplings',\n",
              " 'also.rich',\n",
              " 'loses',\n",
              " 'refreshing',\n",
              " 'identify',\n",
              " 'etc.yum',\n",
              " 'tarter',\n",
              " '305332',\n",
              " 'steaks.i',\n",
              " 'nyc.i',\n",
              " 'seriesgoes',\n",
              " 'here-the',\n",
              " 'french/pitta',\n",
              " 're-heated',\n",
              " 'steakhouses',\n",
              " 'operated',\n",
              " 'cheaper',\n",
              " 'stouffer',\n",
              " 'trentino',\n",
              " 'caulitatoes',\n",
              " 'tastefull',\n",
              " '41577.',\n",
              " 'sandwich.easy',\n",
              " 'helpers',\n",
              " 'immitate',\n",
              " 'bell',\n",
              " '94990',\n",
              " 'good.easy',\n",
              " 'pati',\n",
              " 'nearest',\n",
              " 'listed',\n",
              " 'receive',\n",
              " 'couldnt',\n",
              " 'contrast',\n",
              " 'versa',\n",
              " 'tin.from',\n",
              " 'kid-pleasing',\n",
              " 'loooking',\n",
              " 'ever.my',\n",
              " 'first.tender',\n",
              " 'archer',\n",
              " '18this',\n",
              " 'scientific',\n",
              " 'schloss.my',\n",
              " 'cool.this',\n",
              " 'spicy-food',\n",
              " 'raising',\n",
              " 'enlighten',\n",
              " 'alba',\n",
              " 'alcoholic',\n",
              " 'oomph',\n",
              " 'own.if',\n",
              " 'finaly',\n",
              " 'co-worker',\n",
              " 'adornment',\n",
              " 'noodles.i',\n",
              " 'christmastime',\n",
              " 'bind',\n",
              " 'kurti',\n",
              " 'these.i',\n",
              " 'eating.creamy',\n",
              " 'brioche',\n",
              " 'earthly',\n",
              " 'dish.something',\n",
              " 'producing',\n",
              " 'stack',\n",
              " \"o'clock\",\n",
              " 'unorthodox',\n",
              " 'fend',\n",
              " 'saturated',\n",
              " 'time/life',\n",
              " 'familycrockpotrecipes.com',\n",
              " 'procedure',\n",
              " 'combination',\n",
              " 'before.updated',\n",
              " 'printable',\n",
              " 'hominy',\n",
              " 'freezing.had',\n",
              " 'drfuhrman.com',\n",
              " 'pomi',\n",
              " 'urbana-champaign',\n",
              " 'www.domesticgoddess.com',\n",
              " 'ricardomango',\n",
              " 'partake',\n",
              " 'plane',\n",
              " 'tea.a',\n",
              " 'approximatethis',\n",
              " 'juice.open',\n",
              " 'hte',\n",
              " 'snacking.this',\n",
              " 'border',\n",
              " 'time.for',\n",
              " 'wellthis',\n",
              " 'speed',\n",
              " 'given',\n",
              " 'kosher',\n",
              " 'dives.recipe',\n",
              " 'mix-in',\n",
              " 'variations.recipe',\n",
              " 'clintons',\n",
              " 'recipeseasy',\n",
              " 'card',\n",
              " 'waking',\n",
              " 'dram',\n",
              " 'bullet',\n",
              " '1996',\n",
              " 'tomates',\n",
              " 'sara',\n",
              " 'cupcakes.posted',\n",
              " 'davinci',\n",
              " 'raids',\n",
              " 'brunt',\n",
              " 'ball.as',\n",
              " 'nw',\n",
              " 'incisions',\n",
              " 'cream.great',\n",
              " 'waaaay',\n",
              " 'defer',\n",
              " 'venturing',\n",
              " '1988',\n",
              " 'time.i',\n",
              " 'overall',\n",
              " 'wiping',\n",
              " 'buffet.there',\n",
              " '01/14/2014',\n",
              " 'e.g.',\n",
              " 'authentically',\n",
              " 'klita',\n",
              " 'saunders',\n",
              " 'bechemel',\n",
              " 'manager',\n",
              " 'perk.i',\n",
              " 'dana',\n",
              " 'to.from',\n",
              " 'pleading',\n",
              " '4-5',\n",
              " 'theveggiegal.com',\n",
              " 'carlucci-rodriguez',\n",
              " 'bourbon-mustard',\n",
              " 'tender.the',\n",
              " '1997.you',\n",
              " 'dark-gold',\n",
              " 'sorting',\n",
              " 'klatsch',\n",
              " 'gü',\n",
              " 'lovely.a',\n",
              " 'elephant',\n",
              " 'deep-gold',\n",
              " '1950s',\n",
              " 'kool',\n",
              " 'sangrita',\n",
              " 'lunches.sweetbreads',\n",
              " 'livingwonderful',\n",
              " 'chimichangas',\n",
              " 'awful',\n",
              " 'gush',\n",
              " 'addition.got',\n",
              " 'mango',\n",
              " 'delectably',\n",
              " 'agree-',\n",
              " '6-7.',\n",
              " 'paprika.in',\n",
              " 'adopting',\n",
              " 'instant.why',\n",
              " '14-yr',\n",
              " 'bramley',\n",
              " 'pretty.brushetta',\n",
              " 'later.serve',\n",
              " 'season.after',\n",
              " 'flavors.these',\n",
              " 'holidays.found',\n",
              " 'girlfriends',\n",
              " 'alma',\n",
              " 'link',\n",
              " 'simple—the',\n",
              " 'chan',\n",
              " 'unbraided',\n",
              " 'flex',\n",
              " 'crackers.a',\n",
              " 'overdoing',\n",
              " 'never-before-tried-fritters',\n",
              " 'magazine.we',\n",
              " 'snugly',\n",
              " 'develope',\n",
              " 'hicks-sterns',\n",
              " 'works',\n",
              " 'messed',\n",
              " 'terribly',\n",
              " 'www.pickypalate.blogspot.comtaken',\n",
              " 'slimmed',\n",
              " 'tastythe',\n",
              " 'ml',\n",
              " '1972a',\n",
              " 'pirates',\n",
              " 'locker',\n",
              " 'sworn',\n",
              " 'keepa',\n",
              " 'szechwan',\n",
              " 'circulating',\n",
              " 'icing',\n",
              " 'none.this',\n",
              " 'mix.really',\n",
              " 'sept',\n",
              " 'contrast.a',\n",
              " 'reverse-engineered',\n",
              " 'potato.as',\n",
              " 'nutritionaction',\n",
              " 'ethiopia',\n",
              " '1996.i',\n",
              " '911',\n",
              " 'birth',\n",
              " 'would.my',\n",
              " 'necessary',\n",
              " 'tbsp',\n",
              " 'wendy',\n",
              " 'keren',\n",
              " 'sold.when',\n",
              " 'lava-like',\n",
              " 'longer',\n",
              " 'deliziosa',\n",
              " 'mustard-chipotle',\n",
              " 'basketcase',\n",
              " 'spread.this',\n",
              " 'locally',\n",
              " 'healthy-ish',\n",
              " 'glued',\n",
              " 'optional.from',\n",
              " 'nourishing',\n",
              " 'apricots.from',\n",
              " 'bodkinsthis',\n",
              " 'them.lunchbox',\n",
              " 'not-so-ripe',\n",
              " 'helicobacter',\n",
              " 'proprietors',\n",
              " 'good.delicious',\n",
              " 'calories/carbs',\n",
              " 'beans.slow',\n",
              " 'ohsheglows.com',\n",
              " 'good.smoked',\n",
              " 'alligator',\n",
              " 'complicated.fried',\n",
              " 'substituted',\n",
              " 'recipe.light',\n",
              " '217',\n",
              " 'restaurant.a',\n",
              " 'proteins',\n",
              " 'chickengot',\n",
              " 'thing.if',\n",
              " 'replicating',\n",
              " 'pointsi',\n",
              " 'dessertsa',\n",
              " 'buzz',\n",
              " 'heaven-',\n",
              " 'dives.this',\n",
              " 'soyfoods',\n",
              " 'cupcakeproject.comi',\n",
              " 'braising.these',\n",
              " 'flavoring',\n",
              " 'gracias',\n",
              " 'uh',\n",
              " 'simplest',\n",
              " 'now.my',\n",
              " 'non-dieters',\n",
              " 'ones.this',\n",
              " 'supper.i',\n",
              " 'clog',\n",
              " 'unite',\n",
              " 'met',\n",
              " 'cold.easy',\n",
              " '0',\n",
              " 'entering',\n",
              " 'cheese.i',\n",
              " 'potatoes.i',\n",
              " \"'vegetable\",\n",
              " 'literally',\n",
              " 'mushrooms.ready',\n",
              " 'deliver',\n",
              " 'miami',\n",
              " 'mouseplanet.com',\n",
              " 'has',\n",
              " 'often.found',\n",
              " 'louisville',\n",
              " 'sultana',\n",
              " 'gallons.you',\n",
              " 'refrigerator.this',\n",
              " 'insane',\n",
              " 'anti-fungal',\n",
              " 'included.tasty',\n",
              " 'house.i',\n",
              " 'planned',\n",
              " 'menus.my',\n",
              " '21,04',\n",
              " 'fiddling',\n",
              " 'bowl.cool',\n",
              " 'grange',\n",
              " 'manganese.easy',\n",
              " 'serving.taken',\n",
              " 'broiler-safe',\n",
              " 'delicias',\n",
              " 'homea',\n",
              " 'ahhhh',\n",
              " 'flakiest',\n",
              " 'cake/brownies',\n",
              " 'breakfast.grunts',\n",
              " 'heat.the',\n",
              " 'yummmmmmrefreshing',\n",
              " 'transports',\n",
              " 'guess-timate.for',\n",
              " 'charge',\n",
              " 'khoudrdaji',\n",
              " 'added.the',\n",
              " 'sliced',\n",
              " 'merlot.got',\n",
              " 'top/middle',\n",
              " 'overcooked',\n",
              " 'swampsoggin',\n",
              " 'skateboarder',\n",
              " 'swtich',\n",
              " 'un',\n",
              " 'htis',\n",
              " '214699',\n",
              " '39997',\n",
              " 'wickedly-good',\n",
              " 'portugal.the',\n",
              " 'lj',\n",
              " 'accidentally',\n",
              " 'plan',\n",
              " '10.9',\n",
              " 'makings',\n",
              " 'documented',\n",
              " 'condensation',\n",
              " 'two-cup',\n",
              " 'tribes',\n",
              " 'reasonable',\n",
              " 'soon.note',\n",
              " 'saucepan',\n",
              " 'lusciously',\n",
              " 'sliver',\n",
              " 'strengths.we',\n",
              " 'spicy.light',\n",
              " 'postorder=asc',\n",
              " 'tinned',\n",
              " 'mealtime',\n",
              " 'lucious',\n",
              " '9/10/07',\n",
              " 'sites.i',\n",
              " 'gimli',\n",
              " 'hagan',\n",
              " 'crucial',\n",
              " 'local',\n",
              " 'plugra',\n",
              " 'feeders',\n",
              " 'coffees.these',\n",
              " 'appearances',\n",
              " 'well.tasty5-ingredient',\n",
              " 'crunchy-',\n",
              " 'menu',\n",
              " '8:30',\n",
              " 'wonderful-there',\n",
              " 'guests.they',\n",
              " 'adjusted.this',\n",
              " 'omit',\n",
              " 'clippng',\n",
              " 'chewier',\n",
              " 'rice.light',\n",
              " 'here.delish.comstart',\n",
              " 'delicious.posted',\n",
              " 'mixologist',\n",
              " 'kopanisti',\n",
              " 'average.this',\n",
              " 'harlem',\n",
              " 'recipe.piccadilly',\n",
              " 'lover',\n",
              " 'preferencethis',\n",
              " 'dishes.a',\n",
              " 'peel.i',\n",
              " 'r.d.',\n",
              " 'marcia',\n",
              " 'quicker.found',\n",
              " 'palmi',\n",
              " 'peanuts.chiles',\n",
              " 'bowtie',\n",
              " 'heavy',\n",
              " 'nightly',\n",
              " 'pudding-like',\n",
              " 'well.marie',\n",
              " 'cabbage.adapted',\n",
              " 'kick-ass',\n",
              " 'quick-prep',\n",
              " 'snacky',\n",
              " 'guesstimations',\n",
              " 'desssert',\n",
              " 'radar',\n",
              " 'schlossi',\n",
              " '8this',\n",
              " 'kindersely',\n",
              " 'win/win',\n",
              " 'too.thanksgiving',\n",
              " 'leftovers.we',\n",
              " 'overs.recipe',\n",
              " 'fret',\n",
              " 'simplicity',\n",
              " 'jalapeños.i',\n",
              " 'soakings',\n",
              " 'assertive',\n",
              " 'shadowsthis',\n",
              " 'cold-weather',\n",
              " 'newest',\n",
              " '//www.thebackhomebakery.com/tutorials/shaping.html',\n",
              " 'bonbons',\n",
              " 'newbies',\n",
              " '50g',\n",
              " 'deficient',\n",
              " 'lukily',\n",
              " 'copeland',\n",
              " 'sherriei',\n",
              " 'tongues',\n",
              " 'chill.although',\n",
              " 'door',\n",
              " 'volunteered',\n",
              " 'long-bladed',\n",
              " 'belly',\n",
              " 'likei',\n",
              " 'triple',\n",
              " 'control',\n",
              " 'cinch',\n",
              " 'tart/sweet',\n",
              " '214731',\n",
              " 'flier',\n",
              " 'perfectly.my',\n",
              " 'rice.not',\n",
              " 'sounds',\n",
              " '1997-1998',\n",
              " 'tarte',\n",
              " 'dough.a',\n",
              " '80983this',\n",
              " 'remade',\n",
              " 'stated.i',\n",
              " 'sauce/syrup',\n",
              " 'grasslands',\n",
              " 'motor',\n",
              " 'tastymy',\n",
              " 'australia/',\n",
              " 'conncoction',\n",
              " 'fred',\n",
              " 'alterations',\n",
              " 'red-sauced',\n",
              " 'milk.tastes',\n",
              " 'calories.one',\n",
              " '2007.found',\n",
              " 'myrtle',\n",
              " 'escoffier',\n",
              " 'chunk',\n",
              " 'deviened',\n",
              " 'versatile.a',\n",
              " 'before-hand',\n",
              " 'coated',\n",
              " 'delicious-sounding',\n",
              " 'vegetables',\n",
              " 'step-son',\n",
              " 'online.yummy',\n",
              " 'family-friendly',\n",
              " 'refill',\n",
              " 'w/fruit',\n",
              " 'maincourse',\n",
              " 'sued',\n",
              " 'author.quick',\n",
              " 'homemakers',\n",
              " 'flour.',\n",
              " 'laundromat',\n",
              " 'multi-tasking',\n",
              " 'invitations',\n",
              " 'maris',\n",
              " 'dusted',\n",
              " 'sausage/spinach',\n",
              " 'mommom',\n",
              " 'family.pancetta',\n",
              " 'enjoys.yummy',\n",
              " 'rack',\n",
              " 'searing',\n",
              " 'salads.another',\n",
              " '411',\n",
              " 'banquet',\n",
              " 'mingling',\n",
              " 'no-holds-barred',\n",
              " 'salvatore',\n",
              " 'band',\n",
              " 'enchiladasthis',\n",
              " 'mccoy',\n",
              " 'saltine',\n",
              " 'vermontsource',\n",
              " 'matilda',\n",
              " 'timeposted',\n",
              " 'paid',\n",
              " 'pollution',\n",
              " 'atar',\n",
              " 'foods/hellmans',\n",
              " 'compromise',\n",
              " 'points.a',\n",
              " 'panama',\n",
              " 'onions.mediterranean',\n",
              " 'complete',\n",
              " 'buried',\n",
              " 'vah-ter-zoy',\n",
              " 'wisk',\n",
              " 'carniverous',\n",
              " 'opinion.i',\n",
              " 'rim',\n",
              " 'shops.i',\n",
              " 'decide',\n",
              " 'bowling',\n",
              " 'min.this',\n",
              " 'hourposted',\n",
              " '87',\n",
              " 'tv.this',\n",
              " 'scrambled',\n",
              " 'paralyzer',\n",
              " 'touches',\n",
              " 'pepper/buttered',\n",
              " 'philadelphians',\n",
              " '36.5',\n",
              " 'either.this',\n",
              " 'cream.so',\n",
              " 'sensation.i',\n",
              " 'persistance',\n",
              " 'breakfast.my',\n",
              " 'advertiser',\n",
              " 'marbella',\n",
              " 'poucefrom',\n",
              " 'appreciate',\n",
              " 'mini-carrots',\n",
              " 'liberty',\n",
              " 'carrots.because',\n",
              " 'buffet.absolut',\n",
              " '205185.i',\n",
              " 'comfortable',\n",
              " 'assuming',\n",
              " 'pre-heat',\n",
              " 'mueslis',\n",
              " 'angola',\n",
              " 'roots',\n",
              " 'ingredients.finally',\n",
              " 'uyghurs',\n",
              " 'catfish.a',\n",
              " 'magazineanother',\n",
              " 'solid',\n",
              " ...]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words = pd.read_csv(\"recipes_sample.csv\")\n",
        "words11 = list(set (word_tokenize(''.join(words['description'].fillna('').values))))\n",
        "words11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-qwPQLuZcj2"
      },
      "source": [
        "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBccVX-hR6N-",
        "outputId": "7688e4da-57f7-4ea1-be90-d301d42230e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "слово 1: zwt7, слово 2: comparison. Расстояние: 10\n",
            "слово 1: poucefrom, слово 2: tree-house. Расстояние: 9\n",
            "слово 1: 282040, слово 2: decadent.these. Расстояние: 14\n",
            "слово 1: r.d., слово 2: offer. Расстояние: 5\n",
            "слово 1: -germanyi, слово 2: unbelievely. Расстояние: 10\n"
          ]
        }
      ],
      "source": [
        "words=words11\n",
        "for i in range(5):\n",
        "    pair = np.random.randint(low=0, high=len(words), size=(2))\n",
        "    print(f'слово 1: {words[pair[0]]}, слово 2: {words[pair[1]]}. Расстояние: {nltk.edit_distance(words[pair[0]], words[pair[1]], substitution_cost=1)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5g8pyFzOZcj2"
      },
      "source": [
        "1.3 Напишите функцию, которая для заданного слова `word` возвращает `k` ближайших к нему слов из списка `words` (близость слов измеряется с помощью расстояния Левенштейна)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sofGKF2R6N-",
        "outputId": "e7374ff3-802c-40c0-a092-181de3d41d41"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['cooled', 'cooler', 'cools']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def find_clos(word, k, words):\n",
        "    def srt(t,lv):\n",
        "        for j in range(k-1):\n",
        "            for i in range(k-j-1):\n",
        "                if lv[i] < lv[i+1]:\n",
        "                    lv[i], lv[i+1] = lv[i+1], lv[i]\n",
        "                    t[i], t[i+1] = t[i+1], t[i]\n",
        "        return(t,lv)\n",
        "    t=[]\n",
        "    lv=[]\n",
        "    for i in range (len(words)):\n",
        "        if i<k:\n",
        "            t.append(words[i])\n",
        "            lv.append(lev(word, words[i]))\n",
        "        elif lev(word, words[i]) < lv[0]:\n",
        "            lv[0]=lev(word, words[i])\n",
        "            t[0]=words[i]\n",
        "            t,lv=srt(t, lv)\n",
        "    return(t)\n",
        "find_clos(\"coole\", 3, words11)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bIw4k_pZcj2"
      },
      "source": [
        "### Стемминг, лемматизация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYPqlxh4Zcj3"
      },
      "source": [
        "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами: \n",
        "    * word\n",
        "    * stemmed_word \n",
        "    * normalized_word \n",
        "\n",
        "Столбец `word` укажите в качестве индекса. \n",
        "\n",
        "Для стемминга воспользуйтесь `SnowballStemmer`, для нормализации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9p2AcKrR6OA",
        "outputId": "3d5333d5-3687-44f6-c657-25364d247861"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>stemmed_word</th>\n",
              "      <th>normalized_word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tapenade</td>\n",
              "      <td>[tapenad]</td>\n",
              "      <td>[tapenade]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tasteposting</td>\n",
              "      <td>[tastepost]</td>\n",
              "      <td>[tasteposting]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>served-</td>\n",
              "      <td>[served-]</td>\n",
              "      <td>[served-]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tastes.we</td>\n",
              "      <td>[tastes.w]</td>\n",
              "      <td>[tastes.we]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>101039</td>\n",
              "      <td>[101039]</td>\n",
              "      <td>[101039]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           word stemmed_word normalized_word\n",
              "0      tapenade    [tapenad]      [tapenade]\n",
              "1  tasteposting  [tastepost]  [tasteposting]\n",
              "2       served-    [served-]       [served-]\n",
              "3     tastes.we   [tastes.w]     [tastes.we]\n",
              "4        101039     [101039]        [101039]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('wordnet')\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "words21=pd.DataFrame(words11)\n",
        "words21.columns = ['word']\n",
        "snb = SnowballStemmer('english')\n",
        "words21['stemmed_word']=words21['word'].apply(lambda x: [snb.stem(x)])\n",
        "words21['normalized_word']=words21['word'].apply(lambda x: [wordnet_lemmatizer.lemmatize(x)])\n",
        "words21.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS6jm5LFZcj3"
      },
      "source": [
        "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuENGBE8R6OB"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "with open('recipes_sample.csv', newline='', encoding=\"utf8\") as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "    for row in reader:\n",
        "        data.append(row)\n",
        "all_texts = ''\n",
        "all_texts_list = []\n",
        "for row in data:\n",
        "    all_texts += row['description']\n",
        "    all_texts += ' '\n",
        "    all_texts_list.append(row['description'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQKkXiOfR6OB",
        "outputId": "17fdf3a2-6028-4873-d3d0-8a5b4dcc86b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Кол-во слов до удаления: 1077341\n",
            "Топ-10 до удаления:\n",
            "[('the', 39883), ('a', 34869), ('and', 30059), ('this', 26115), ('i', 24892), ('to', 23366), ('is', 20051), ('of', 18320), ('it', 16917), ('for', 15793)]\n",
            "597450\n",
            "Кол-во слов после удаления: 4121618\n",
            "Топ-10 после удаления:\n",
            "[('recipe', 12302), ('make', 5540), ('use', 4484), ('great', 4047), ('like', 3792), ('made', 3706), ('time', 3609), ('one', 3446), ('easy', 3374), ('good', 2594)]\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "words=words11\n",
        "varsn_stop_words = stopwords.words('english')\n",
        "words = all_texts.split()\n",
        "\n",
        "print(f'Кол-во слов до удаления: {len(words)}')\n",
        "\n",
        "# топ-10 самых часто употребляемых слов до удаления стоп-слов\n",
        "fdist_before = FreqDist(all_texts.split())\n",
        "print(f'Топ-10 до удаления:')\n",
        "print(fdist_before.most_common(10))\n",
        "\n",
        "# Удалите стоп-слова из описаний рецептов\n",
        "words = [word for word in words if word not in varsn_stop_words]#en_stop_words]\n",
        "print(len(words))\n",
        "words = ' '.join(words)\n",
        "\n",
        "# топ-10 самых часто употребляемых после удаления стоп-слов\n",
        "print(f'Кол-во слов после удаления: {len(words)}')\n",
        "\n",
        "fdist_after = FreqDist(words.split())\n",
        "print(f'Топ-10 после удаления:')\n",
        "print(fdist_after.most_common(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZViwhPbZcj3"
      },
      "source": [
        "### Векторное представление текста"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rM3puht1Zcj3"
      },
      "source": [
        "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbwzowKyR6OD",
        "outputId": "115de4ea-df6f-4ca0-ff2a-0e3d8fc0e9dc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>versatile</th>\n",
              "      <th>delicious</th>\n",
              "      <th>meatballs</th>\n",
              "      <th>edited</th>\n",
              "      <th>to</th>\n",
              "      <th>suit</th>\n",
              "      <th>my</th>\n",
              "      <th>family</th>\n",
              "      <th>tastes</th>\n",
              "      <th>fabulous</th>\n",
              "      <th>...</th>\n",
              "      <th>tasting</th>\n",
              "      <th>bread</th>\n",
              "      <th>excellent</th>\n",
              "      <th>that</th>\n",
              "      <th>be</th>\n",
              "      <th>used</th>\n",
              "      <th>make</th>\n",
              "      <th>cinnamon</th>\n",
              "      <th>rolls</th>\n",
              "      <th>yum</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>meatballs  made with oatmeal</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.346742</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>minestra di piselli  green pea soup</th>\n",
              "      <td>0.088684</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.088684</td>\n",
              "      <td>0.088684</td>\n",
              "      <td>0.071550</td>\n",
              "      <td>0.088684</td>\n",
              "      <td>0.178178</td>\n",
              "      <td>0.088684</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.088684</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.088684</td>\n",
              "      <td>0.177368</td>\n",
              "      <td>0.071550</td>\n",
              "      <td>0.071550</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>green bean and celery casserole</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.150043</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100485</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.300086</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.150043</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.150043</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zucchini with jalapeno monterey jack</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.427993</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.63907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cream cheese yeast bread  bread machine</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.205131</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.254255</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.205131</td>\n",
              "      <td>0.205131</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.254255</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 112 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         versatile  delicious  meatballs  \\\n",
              "name                                                                       \n",
              "meatballs  made with oatmeal              0.000000   0.000000   0.000000   \n",
              "minestra di piselli  green pea soup       0.088684   0.000000   0.088684   \n",
              "green bean and celery casserole           0.000000   0.150043   0.000000   \n",
              "zucchini with jalapeno monterey jack      0.000000   0.000000   0.000000   \n",
              "cream cheese yeast bread  bread machine   0.000000   0.000000   0.000000   \n",
              "\n",
              "                                           edited        to      suit  \\\n",
              "name                                                                    \n",
              "meatballs  made with oatmeal             0.000000  0.000000  0.000000   \n",
              "minestra di piselli  green pea soup      0.088684  0.071550  0.088684   \n",
              "green bean and celery casserole          0.000000  0.000000  0.000000   \n",
              "zucchini with jalapeno monterey jack     0.000000  0.000000  0.000000   \n",
              "cream cheese yeast bread  bread machine  0.000000  0.205131  0.000000   \n",
              "\n",
              "                                               my    family    tastes  \\\n",
              "name                                                                    \n",
              "meatballs  made with oatmeal             0.000000  0.000000  0.000000   \n",
              "minestra di piselli  green pea soup      0.178178  0.088684  0.000000   \n",
              "green bean and celery casserole          0.100485  0.000000  0.300086   \n",
              "zucchini with jalapeno monterey jack     0.427993  0.000000  0.000000   \n",
              "cream cheese yeast bread  bread machine  0.000000  0.000000  0.000000   \n",
              "\n",
              "                                         fabulous  ...   tasting     bread  \\\n",
              "name                                               ...                       \n",
              "meatballs  made with oatmeal             0.000000  ...  0.000000  0.000000   \n",
              "minestra di piselli  green pea soup      0.088684  ...  0.000000  0.000000   \n",
              "green bean and celery casserole          0.000000  ...  0.000000  0.150043   \n",
              "zucchini with jalapeno monterey jack     0.000000  ...  0.000000  0.000000   \n",
              "cream cheese yeast bread  bread machine  0.000000  ...  0.254255  0.000000   \n",
              "\n",
              "                                         excellent      that        be  \\\n",
              "name                                                                     \n",
              "meatballs  made with oatmeal              0.346742  0.000000  0.000000   \n",
              "minestra di piselli  green pea soup       0.000000  0.088684  0.177368   \n",
              "green bean and celery casserole           0.000000  0.000000  0.000000   \n",
              "zucchini with jalapeno monterey jack      0.000000  0.000000  0.000000   \n",
              "cream cheese yeast bread  bread machine   0.000000  0.000000  0.000000   \n",
              "\n",
              "                                             used      make  cinnamon  \\\n",
              "name                                                                    \n",
              "meatballs  made with oatmeal             0.000000  0.000000  0.000000   \n",
              "minestra di piselli  green pea soup      0.071550  0.071550  0.000000   \n",
              "green bean and celery casserole          0.000000  0.000000  0.150043   \n",
              "zucchini with jalapeno monterey jack     0.000000  0.000000  0.000000   \n",
              "cream cheese yeast bread  bread machine  0.205131  0.205131  0.000000   \n",
              "\n",
              "                                            rolls      yum  \n",
              "name                                                        \n",
              "meatballs  made with oatmeal             0.000000  0.00000  \n",
              "minestra di piselli  green pea soup      0.000000  0.00000  \n",
              "green bean and celery casserole          0.000000  0.00000  \n",
              "zucchini with jalapeno monterey jack     0.000000  0.63907  \n",
              "cream cheese yeast bread  bread machine  0.254255  0.00000  \n",
              "\n",
              "[5 rows x 112 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "words = pd.read_csv(\"recipes_sample.csv\")\n",
        "sample = words.sample(5)#get_feature_names_out()\n",
        "tfidf = pd.DataFrame(vectorizer.fit_transform(sample.description).toarray(), columns=vectorizer.vocabulary_, index=sample.name)\n",
        "tfidf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWVFV678Zcj4"
      },
      "source": [
        "3.2 Вычислите близость между каждой парой рецептов, выбранных в задании 3.1, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEAKMTM9R6OE",
        "outputId": "3546090c-1310-4584-b36d-dc96d1ca3515"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>meatballs  made with oatmeal</th>\n",
              "      <th>minestra di piselli  green pea soup</th>\n",
              "      <th>green bean and celery casserole</th>\n",
              "      <th>zucchini with jalapeno monterey jack</th>\n",
              "      <th>cream cheese yeast bread  bread machine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>meatballs  made with oatmeal</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.970719</td>\n",
              "      <td>0.966974</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.972018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>minestra di piselli  green pea soup</th>\n",
              "      <td>0.970719</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.755217</td>\n",
              "      <td>0.923741</td>\n",
              "      <td>0.859142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>green bean and celery casserole</th>\n",
              "      <td>0.966974</td>\n",
              "      <td>0.755217</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.956993</td>\n",
              "      <td>0.882510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zucchini with jalapeno monterey jack</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.923741</td>\n",
              "      <td>0.956993</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cream cheese yeast bread  bread machine</th>\n",
              "      <td>0.972018</td>\n",
              "      <td>0.859142</td>\n",
              "      <td>0.882510</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         meatballs  made with oatmeal  \\\n",
              "meatballs  made with oatmeal                                 0.000000   \n",
              "minestra di piselli  green pea soup                          0.970719   \n",
              "green bean and celery casserole                              0.966974   \n",
              "zucchini with jalapeno monterey jack                         1.000000   \n",
              "cream cheese yeast bread  bread machine                      0.972018   \n",
              "\n",
              "                                         minestra di piselli  green pea soup  \\\n",
              "meatballs  made with oatmeal                                        0.970719   \n",
              "minestra di piselli  green pea soup                                 0.000000   \n",
              "green bean and celery casserole                                     0.755217   \n",
              "zucchini with jalapeno monterey jack                                0.923741   \n",
              "cream cheese yeast bread  bread machine                             0.859142   \n",
              "\n",
              "                                         green bean and celery casserole  \\\n",
              "meatballs  made with oatmeal                                    0.966974   \n",
              "minestra di piselli  green pea soup                             0.755217   \n",
              "green bean and celery casserole                                 0.000000   \n",
              "zucchini with jalapeno monterey jack                            0.956993   \n",
              "cream cheese yeast bread  bread machine                         0.882510   \n",
              "\n",
              "                                         zucchini with jalapeno monterey jack  \\\n",
              "meatballs  made with oatmeal                                         1.000000   \n",
              "minestra di piselli  green pea soup                                  0.923741   \n",
              "green bean and celery casserole                                      0.956993   \n",
              "zucchini with jalapeno monterey jack                                 0.000000   \n",
              "cream cheese yeast bread  bread machine                              1.000000   \n",
              "\n",
              "                                         cream cheese yeast bread  bread machine  \n",
              "meatballs  made with oatmeal                                            0.972018  \n",
              "minestra di piselli  green pea soup                                     0.859142  \n",
              "green bean and celery casserole                                         0.882510  \n",
              "zucchini with jalapeno monterey jack                                    1.000000  \n",
              "cream cheese yeast bread  bread machine                                 0.000000  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "distances = pd.DataFrame()\n",
        "for i in tfidf.iterrows():\n",
        "    for j in tfidf.iterrows():\n",
        "        distances.loc[i[0], j[0]] = cosine(i[1].values, j[1].values)\n",
        "distances"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}